# -*- coding: utf-8 -*-
import streamlit as st
import jieba
import requests
from bs4 import BeautifulSoup
from collections import Counter
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import re

# é¡µé¢åŸºç¡€é…ç½®
st.set_page_config(page_title="URLè¯é¢‘åˆ†æç³»ç»Ÿ", page_icon="ğŸ“Š", layout="wide")

# å›ºå®šæµ‹è¯•æ–‡æœ¬ï¼ˆçˆ¬å–å¤±è´¥æ—¶å…œåº•ï¼‰
TEST_TEXT = """äººå·¥æ™ºèƒ½æ˜¯ä¸€é—¨æ—¨åœ¨ä½¿è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿæ¨¡æ‹Ÿã€å»¶ä¼¸å’Œæ‰©å±•äººç±»æ™ºèƒ½çš„æŠ€æœ¯ç§‘å­¦ã€‚å®ƒæ¶µç›–äº†æœºå™¨å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€ä¸“å®¶ç³»ç»Ÿç­‰å¤šä¸ªé¢†åŸŸã€‚æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒï¼Œé€šè¿‡è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ï¼Œè€Œæ— éœ€æ˜¾å¼ç¼–ç¨‹ã€‚æ·±åº¦å­¦ä¹ ä½œä¸ºæœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿäººè„‘ç»“æ„ï¼Œåœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚è‡ªç„¶è¯­è¨€å¤„ç†åˆ™ä¸“æ³¨äºè®©è®¡ç®—æœºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ï¼Œå¦‚èŠå¤©æœºå™¨äººã€æœºå™¨ç¿»è¯‘ç­‰åº”ç”¨ã€‚äººå·¥æ™ºèƒ½çš„å‘å±•å·²ç»æ·±åˆ»å½±å“äº†åŒ»ç–—ã€é‡‘èã€äº¤é€šã€æ•™è‚²ç­‰å„è¡Œå„ä¸šï¼Œæœªæ¥è¿˜å°†ç»§ç»­æ¨åŠ¨ç¤¾ä¼šçš„æ•°å­—åŒ–è½¬å‹ã€‚"""

# æ–°å¢ï¼šURLçˆ¬å–å‡½æ•°
def crawl_url_text(url):
    """çˆ¬å–æŒ‡å®šURLçš„ä¸­æ–‡æ–‡æœ¬å†…å®¹"""
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
        }
        resp = requests.get(url, headers=headers, timeout=15, verify=False)
        resp.encoding = resp.apparent_encoding or "utf-8"
        soup = BeautifulSoup(resp.text, "html.parser")
        p_text = "\n".join([p.get_text(strip=True) for p in soup.find_all("p") if len(p.get_text(strip=True))>5])
        art_text = soup.find("article").get_text(strip=True) if soup.find("article") else ""
        raw_text = p_text if len(p_text) > len(art_text) else art_text
        clean_text = re.sub(r"[^\u4e00-\u9fa5\s]", "", re.sub(r"\s+", " ", raw_text))
        return clean_text if len(clean_text) > 50 else None
    except Exception as e:
        st.error(f"URLçˆ¬å–å¤±è´¥ï¼š{str(e)}")
        return None

# 1. æ–‡æœ¬åˆ†æï¼ˆç”Ÿæˆå¸¦ç¼–å·çš„è¯æ±‡è¡¨ï¼‰
def analyze_text(text, min_freq=1):
    stop_words = {'çš„','äº†','æ˜¯','åœ¨','å’Œ','æœ‰','å°±','éƒ½','è¿™','é‚£','ä¸ª','ä¸º','æŠŠ','æˆ‘','ä½ ','ä»–','å¥¹','å®ƒ','æˆ‘ä»¬','ä½ ä»¬','ä»–ä»¬','è¿™é‡Œ','é‚£é‡Œ','ä»€ä¹ˆ','æ€ä¹ˆ','ä¸ºä»€ä¹ˆ','å¦‚ä½•','ç„¶å','ä½†æ˜¯','å¦‚æœ','å› ä¸º','æ‰€ä»¥','è™½ç„¶','æ—¢ç„¶','ä¹‹','äº','ä¹Ÿ','è¿˜','åŠ','ä¸','æˆ–','å³','æ‰€','å°†','ä¼š','å¯','èƒ½','åº”','è¯¥','è¦','éœ€','é¡»','å¾—','è¿‡','ç€','å•Š','å‘€','å‘¢','å—','å§'}
    words = [w for w in jieba.lcut(text) if w not in stop_words and len(w)>1]
    word_freq = Counter(words)
    top10 = sorted(word_freq.items(), key=lambda x:x[1], reverse=True)[:10]
    df = pd.DataFrame(top10, columns=["è¯æ±‡", "è¯é¢‘"])
    df["ç¼–å·"] = [f"#{i+1}" for i in range(len(df))]
    return df

# 2. å›¾è¡¨ç”Ÿæˆï¼ˆæ ¸å¿ƒä¿®æ”¹ï¼šå»æ‰æ ‡é¢˜åçš„æ–¹æ¡†ï¼‰
def render_chart(df, chart_type):
    df_chart = df.copy()
    df_chart["æ˜¾ç¤ºæ ‡ç­¾"] = df_chart["ç¼–å·"]
    df_chart = df_chart.set_index("æ˜¾ç¤ºæ ‡ç­¾")

    if chart_type == "æŸ±çŠ¶å›¾":
        st.bar_chart(df_chart["è¯é¢‘"], use_container_width=True)
    elif chart_type == "æŠ˜çº¿å›¾":
        st.line_chart(df_chart["è¯é¢‘"], use_container_width=True)
    elif chart_type == "é¢ç§¯å›¾":
        st.area_chart(df_chart["è¯é¢‘"], use_container_width=True)
    elif chart_type == "é¥¼å›¾":
        fig, ax = plt.subplots(figsize=(8,8))
        ax.pie(
            df["è¯é¢‘"], 
            labels=df["ç¼–å·"],
            autopct='%1.1f%%',
            colors=plt.cm.Set3(np.linspace(0, 1, len(df)))
        )
        ax.set_title("TOP10è¯æ±‡é¥¼å›¾ï¼ˆç¼–å·å¯¹åº”ä¸‹æ–¹ä¸­æ–‡ï¼‰")  # å»æ‰å¤šä½™æ–¹æ¡†
        st.pyplot(fig)
    elif chart_type == "æ•£ç‚¹å›¾":
        st.scatter_chart(df, x="ç¼–å·", y="è¯é¢‘", size="è¯é¢‘", use_container_width=True)
    elif chart_type == "æ¨ªå‘æŸ±çŠ¶å›¾ï¼ˆæ›¿ä»£è¯äº‘ï¼‰":
        fig, ax = plt.subplots(figsize=(10,6))
        ax.barh(df["ç¼–å·"], df["è¯é¢‘"], color="#4285F4")
        ax.set_xlabel("è¯é¢‘")
        ax.set_ylabel("è¯æ±‡ç¼–å·")
        ax.set_title("TOP10è¯æ±‡æ¨ªå‘æŸ±çŠ¶å›¾ï¼ˆæ›¿ä»£è¯äº‘ï¼‰")  # å»æ‰å¤šä½™æ–¹æ¡†
        st.pyplot(fig)
    elif chart_type == "çƒ­åŠ›å›¾ï¼ˆæ•°å€¼ï¼‰":
        st.dataframe(df_chart[["è¯é¢‘"]].style.background_gradient(cmap="Blues"), use_container_width=True)
    elif chart_type == "æ¼æ–—å›¾ï¼ˆæ’åºï¼‰":
        df_sorted = df.sort_values("è¯é¢‘", ascending=True)
        df_sorted = df_sorted.set_index("ç¼–å·")
        st.bar_chart(df_sorted["è¯é¢‘"], use_container_width=True)

    # å¤–ç½®ä¸­æ–‡æ ‡æ³¨
    st.markdown("### ğŸ“ å›¾è¡¨ç¼–å·-ä¸­æ–‡è¯æ±‡å¯¹åº”è¡¨")
    label_df = df[["ç¼–å·", "è¯æ±‡", "è¯é¢‘"]].set_index("ç¼–å·")
    st.dataframe(label_df, use_container_width=True)

# ======== é¡µé¢å¸ƒå±€ ========
st.title("ğŸ“Š URLè¯é¢‘åˆ†æç³»ç»Ÿï¼ˆæœ€ç»ˆç¨³å®šç‰ˆï¼‰")
st.markdown("### ç½‘å€çˆ¬å–é…ç½®")

url_input = st.text_input(
    label="è¾“å…¥éœ€è¦çˆ¬å–çš„ç½‘ç«™URL",
    placeholder="ç¤ºä¾‹ï¼šhttps://www.guokr.com/article/440923/",
    help="è¯·è¾“å…¥å…¬å¼€çš„ä¸­æ–‡æ–‡ç« ç±»URLï¼ˆå¦‚æ–°é—»ã€åšå®¢ã€å…¬ä¼—å·æ–‡ç« ï¼‰"
)

st.markdown("### åˆ†æé…ç½®é¡¹")
with st.sidebar:
    min_freq = st.slider("æœ€ä½è¯é¢‘è¿‡æ»¤", 1, 5, 1)
    chart_type = st.selectbox(
        "é€‰æ‹©å›¾è¡¨ç±»å‹",
        [
            "æŸ±çŠ¶å›¾", "æŠ˜çº¿å›¾", "é¢ç§¯å›¾", "é¥¼å›¾", 
            "æ•£ç‚¹å›¾", "æ¨ªå‘æŸ±çŠ¶å›¾ï¼ˆæ›¿ä»£è¯äº‘ï¼‰", 
            "çƒ­åŠ›å›¾ï¼ˆæ•°å€¼ï¼‰", "æ¼æ–—å›¾ï¼ˆæ’åºï¼‰"
        ]
    )
    analyze_btn = st.button("ğŸ” å¼€å§‹çˆ¬å–å¹¶åˆ†æ", type="primary")

# æ ¸å¿ƒé€»è¾‘
if analyze_btn:
    if not url_input:
        st.warning("è¯·å…ˆè¾“å…¥éœ€è¦çˆ¬å–çš„URLåœ°å€ï¼")
    else:
        with st.spinner("æ­£åœ¨çˆ¬å–ç½‘é¡µæ–‡æœ¬..."):
            crawled_text = crawl_url_text(url_input)
            target_text = crawled_text if crawled_text else TEST_TEXT
            if not crawled_text:
                st.info("çˆ¬å–å¤±è´¥ï¼Œè‡ªåŠ¨ä½¿ç”¨æµ‹è¯•æ–‡æœ¬è¿›è¡Œåˆ†æ")
        
        df_result = analyze_text(target_text, min_freq)
        st.success("âœ… åˆ†æå®Œæˆï¼")
        st.markdown("### ğŸ“‹ TOP10è¯æ±‡åŸå§‹åˆ—è¡¨")
        st.dataframe(df_result[["è¯æ±‡", "è¯é¢‘"]], use_container_width=True)
        st.markdown(f"### ğŸ“ˆ {chart_type}")
        render_chart(df_result, chart_type)

# é¡µè„šè¯´æ˜
st.divider()
st.caption("ğŸ’¡ å›¾è¡¨å†…ç”¨ç¼–å·ä¿è¯æ ·å¼ï¼Œä¸‹æ–¹æ ‡æ³¨ä¸­æ–‡è¯æ±‡ï¼Œå…¼é¡¾å¯è§†åŒ–æ•ˆæœä¸å¯è¯»æ€§")
