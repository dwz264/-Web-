# -*- coding: utf-8 -*-
import streamlit as st
import jieba
import re
from collections import Counter
import requests
from bs4 import BeautifulSoup
import pandas as pd
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import os

# é¡µé¢é…ç½®
st.set_page_config(page_title="URLè¯é¢‘åˆ†æç³»ç»Ÿ", page_icon="ğŸ“Š", layout="wide")

# åŠ è½½ä¸­æ–‡å­—ä½“ï¼ˆè§£å†³è¯äº‘ä¸­æ–‡æ˜¾ç¤ºï¼‰
font_path = os.path.join(os.path.dirname(__file__), 'SimHei.ttf')

# å…œåº•æ–‡æœ¬
BACKUP_TEXT = """äººå·¥æ™ºèƒ½æ˜¯ä¸€é—¨æ—¨åœ¨ä½¿è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿæ¨¡æ‹Ÿã€å»¶ä¼¸å’Œæ‰©å±•äººç±»æ™ºèƒ½çš„æŠ€æœ¯ç§‘å­¦ã€‚å®ƒæ¶µç›–äº†æœºå™¨å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€ä¸“å®¶ç³»ç»Ÿç­‰å¤šä¸ªé¢†åŸŸã€‚æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒï¼Œé€šè¿‡è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ï¼Œè€Œæ— éœ€æ˜¾å¼ç¼–ç¨‹ã€‚æ·±åº¦å­¦ä¹ ä½œä¸ºæœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿäººè„‘ç»“æ„ï¼Œåœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚è‡ªç„¶è¯­è¨€å¤„ç†åˆ™ä¸“æ³¨äºè®©è®¡ç®—æœºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ï¼Œå¦‚èŠå¤©æœºå™¨äººã€æœºå™¨ç¿»è¯‘ç­‰åº”ç”¨ã€‚äººå·¥æ™ºèƒ½çš„å‘å±•å·²ç»æ·±åˆ»å½±å“äº†åŒ»ç–—ã€é‡‘èã€äº¤é€šã€æ•™è‚²ç­‰å„è¡Œå„ä¸šï¼Œæœªæ¥è¿˜å°†ç»§ç»­æ¨åŠ¨ç¤¾ä¼šçš„æ•°å­—åŒ–è½¬å‹ã€‚"""

# 1. URLæ–‡æœ¬æŠ“å–
def fetch_url_text(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) Chrome/86.0.4240.198 Safari/537.36"}
        resp = requests.get(url, headers=headers, timeout=15, verify=False)
        resp.encoding = resp.apparent_encoding or 'utf-8'
        soup = BeautifulSoup(resp.text, 'html.parser')
        p_text = "\n".join([p.get_text(strip=True) for p in soup.find_all("p") if len(p.get_text(strip=True))>10])
        art_text = soup.find("article").get_text(strip=True) if soup.find("article") else ""
        text = p_text if len(p_text) > len(art_text) else art_text
        return re.sub(r'[^\u4e00-\u9fa5\s]', '', re.sub(r'\s+', ' ', text))
    except Exception as e:
        return f"URLæŠ“å–å¤±è´¥ï¼š{str(e)}"

# 2. æ–‡æœ¬åˆ†æ
def analyze_text(text, min_freq=1):
    stop_words = {'çš„','äº†','æ˜¯','åœ¨','å’Œ','æœ‰','å°±','éƒ½','è¿™','é‚£','ä¸ª','ä¸º','æŠŠ','æˆ‘','ä½ ','ä»–','å¥¹','å®ƒ','æˆ‘ä»¬','ä½ ä»¬','ä»–ä»¬','è¿™é‡Œ','é‚£é‡Œ','ä»€ä¹ˆ','æ€ä¹ˆ','ä¸ºä»€ä¹ˆ','å¦‚ä½•','ç„¶å','ä½†æ˜¯','å¦‚æœ','å› ä¸º','æ‰€ä»¥','è™½ç„¶','æ—¢ç„¶','ä¹‹','äº','ä¹Ÿ','è¿˜','åŠ','ä¸','æˆ–','å³','æ‰€','å°†','ä¼š','å¯','èƒ½','åº”','è¯¥','è¦','éœ€','é¡»','å¾—','è¿‡','ç€','å•Š','å‘€','å‘¢','å—','å§'}
    words = [w for w in jieba.lcut(re.sub(r'\s+', ' ', text)) if w not in stop_words and len(w)>1]
    word_freq = Counter(words)
    return {k:v for k,v in word_freq.items() if v>=min_freq}, sorted(word_freq.items(), key=lambda x:x[1], reverse=True)[:20]

# 3. 8ç§å›¾è¡¨ï¼ˆå«æ ‡å‡†è¯äº‘å›¾ï¼‰
def show_chart(top20, chart_type):
    if not top20:
        st.warning("æš‚æ— æœ‰æ•ˆæ•°æ®")
        return
    df = pd.DataFrame(top20, columns=["è¯æ±‡", "è¯é¢‘"])
    word_freq_dict = dict(top20)

    # 1. æ ‡å‡†è¯äº‘å›¾
    if chart_type == "è¯äº‘å›¾":
        wc = WordCloud(
            font_path=font_path,
            width=800, height=500,
            background_color="white",
            max_words=20
        ).generate_from_frequencies(word_freq_dict)
        fig, ax = plt.subplots(figsize=(10,6))
        ax.imshow(wc)
        ax.axis("off")
        ax.set_title("TOP20è¯æ±‡è¯äº‘å›¾")
        st.pyplot(fig)
    
    # 2. æŸ±çŠ¶å›¾
    elif chart_type == "æŸ±çŠ¶å›¾":
        fig, ax = plt.subplots(figsize=(10,6))
        ax.barh(df["è¯æ±‡"], df["è¯é¢‘"], color="#4285F4")
        ax.set_xlabel("è¯é¢‘")
        ax.set_ylabel("è¯æ±‡")
        ax.set_title("TOP20è¯æ±‡æŸ±çŠ¶å›¾")
        st.pyplot(fig)
    
    # 3. æŠ˜çº¿å›¾
    elif chart_type == "æŠ˜çº¿å›¾":
        fig, ax = plt.subplots(figsize=(10,6))
        ax.plot(df["è¯æ±‡"], df["è¯é¢‘"], marker='o', color="#4285F4")
        plt.xticks(rotation=45)
        ax.set_xlabel("è¯æ±‡")
        ax.set_ylabel("è¯é¢‘")
        ax.set_title("TOP20è¯æ±‡æŠ˜çº¿å›¾")
        st.pyplot(fig)
    
    # 4. é¥¼å›¾
    elif chart_type == "é¥¼å›¾":
        fig, ax = plt.subplots(figsize=(8,8))
        ax.pie(df["è¯é¢‘"], labels=df["è¯æ±‡"], autopct='%1.1f%%')
        ax.set_title("TOP20è¯æ±‡é¥¼å›¾")
        st.pyplot(fig)
    
    # 5. é›·è¾¾å›¾
    elif chart_type == "é›·è¾¾å›¾":
        fig, ax = plt.subplots(figsize=(8,8), subplot_kw=dict(polar=True))
        theta = list(range(len(df))) + [0]
        values = df["è¯é¢‘"].tolist() + [df["è¯é¢‘"].tolist()[0]]
        ax.plot(theta, values, color="#4285F4")
        ax.fill(theta, values, alpha=0.2)
        ax.set_xticks(range(len(df)))
        ax.set_xticklabels(df["è¯æ±‡"])
        ax.set_title("TOP20è¯æ±‡é›·è¾¾å›¾")
        st.pyplot(fig)
    
    # 6. æ•£ç‚¹å›¾
    elif chart_type == "æ•£ç‚¹å›¾":
        fig, ax = plt.subplots(figsize=(10,6))
        ax.scatter(df["è¯æ±‡"], df["è¯é¢‘"], s=df["è¯é¢‘"]*50, color="#4285F4")
        plt.xticks(rotation=45)
        ax.set_xlabel("è¯æ±‡")
        ax.set_ylabel("è¯é¢‘")
        ax.set_title("TOP20è¯æ±‡æ•£ç‚¹å›¾")
        st.pyplot(fig)
    
    # 7. çƒ­åŠ›å›¾
    elif chart_type == "çƒ­åŠ›å›¾":
        fig, ax = plt.subplots(figsize=(10,3))
        im = ax.imshow(df["è¯é¢‘"].values.reshape(1,-1), cmap='Blues')
        ax.set_xticks(range(len(df)))
        ax.set_xticklabels(df["è¯æ±‡"], rotation=45)
        ax.set_yticks([0])
        ax.set_yticklabels(["è¯é¢‘"])
        plt.colorbar(im)
        ax.set_title("TOP20è¯æ±‡çƒ­åŠ›å›¾")
        st.pyplot(fig)
    
    # 8. æ¼æ–—å›¾
    elif chart_type == "æ¼æ–—å›¾":
        fig, ax = plt.subplots(figsize=(10,6))
        widths = df["è¯é¢‘"]/df["è¯é¢‘"].max()*0.8
        for i, (word, freq, w) in enumerate(zip(df["è¯æ±‡"], df["è¯é¢‘"], widths)):
            ax.bar(i, freq, width=w, color="#4285F4", alpha=0.7)
            ax.text(i, freq+0.5, word, ha='center')
        ax.set_xticks([])
        ax.set_title("TOP20è¯æ±‡æ¼æ–—å›¾")
        st.pyplot(fig)

# é¡µé¢å¸ƒå±€
st.title("ğŸ“Š URLæ–‡æœ¬è¯é¢‘åˆ†æç³»ç»Ÿ")
st.subheader("Streamlit Cloudéƒ¨ç½²ç‰ˆ | æ ‡å‡†è¯äº‘å›¾+ä¸­æ–‡æ˜¾ç¤º")

with st.sidebar:
    st.header("âš™ï¸ é…ç½®é¡¹")
    url = st.text_input("æ–‡ç« URL", value="https://www.guokr.com/article/440923/")
    min_freq = st.selectbox("æœ€ä½è¯é¢‘è¿‡æ»¤", [1,2,3,4,5])
    chart_type = st.selectbox("å›¾è¡¨ç±»å‹", ["è¯äº‘å›¾","æŸ±çŠ¶å›¾","æŠ˜çº¿å›¾","é¥¼å›¾","é›·è¾¾å›¾","æ•£ç‚¹å›¾","çƒ­åŠ›å›¾","æ¼æ–—å›¾"])
    analyze_btn = st.button("ğŸš€ æŠ“å–å¹¶åˆ†æ")

# åˆ†æé€»è¾‘
if analyze_btn:
    if not url:
        st.error("è¯·è¾“å…¥URL")
    else:
        text = fetch_url_text(url)
        if text.startswith("URLæŠ“å–å¤±è´¥"):
            st.error(text)
        elif len(text)<50:
            st.warning("ä½¿ç”¨å…œåº•æ–‡æœ¬")
            text = BACKUP_TEXT
        
        word_freq, top20 = analyze_text(text, min_freq)
        if not top20:
            st.error("æ— æœ‰æ•ˆè¯æ±‡")
        else:
            st.success(f"åˆ†ææˆåŠŸï¼æœ‰æ•ˆè¯æ±‡{len(word_freq)}ä¸ª")
            st.table([{"æ’å":i+1, "è¯æ±‡":w, "è¯é¢‘":f} for i,(w,f) in enumerate(top20)])
            st.subheader(f"{chart_type}å¯è§†åŒ–")
            show_chart(top20, chart_type)
