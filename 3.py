# -*- coding: utf-8 -*-
import streamlit as st
import jieba
import re
from collections import Counter
import requests
from bs4 import BeautifulSoup
import pandas as pd

# é¡µé¢é…ç½®
st.set_page_config(page_title="URLè¯é¢‘åˆ†æç³»ç»Ÿ", page_icon="ğŸ“Š", layout="wide")

# å…œåº•æ–‡æœ¬
BACKUP_TEXT = """äººå·¥æ™ºèƒ½æ˜¯ä¸€é—¨æ—¨åœ¨ä½¿è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿæ¨¡æ‹Ÿã€å»¶ä¼¸å’Œæ‰©å±•äººç±»æ™ºèƒ½çš„æŠ€æœ¯ç§‘å­¦ã€‚å®ƒæ¶µç›–äº†æœºå™¨å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€ä¸“å®¶ç³»ç»Ÿç­‰å¤šä¸ªé¢†åŸŸã€‚æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒï¼Œé€šè¿‡è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ï¼Œè€Œæ— éœ€æ˜¾å¼ç¼–ç¨‹ã€‚æ·±åº¦å­¦ä¹ ä½œä¸ºæœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿäººè„‘ç»“æ„ï¼Œåœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚è‡ªç„¶è¯­è¨€å¤„ç†åˆ™ä¸“æ³¨äºè®©è®¡ç®—æœºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ï¼Œå¦‚èŠå¤©æœºå™¨äººã€æœºå™¨ç¿»è¯‘ç­‰åº”ç”¨ã€‚äººå·¥æ™ºèƒ½çš„å‘å±•å·²ç»æ·±åˆ»å½±å“äº†åŒ»ç–—ã€é‡‘èã€äº¤é€šã€æ•™è‚²ç­‰å„è¡Œå„ä¸šï¼Œæœªæ¥è¿˜å°†ç»§ç»­æ¨åŠ¨ç¤¾ä¼šçš„æ•°å­—åŒ–è½¬å‹ã€‚"""

# 1. URLæ–‡æœ¬æŠ“å–
def fetch_url_text(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) Chrome/86.0.4240.198 Safari/537.36"}
        resp = requests.get(url, headers=headers, timeout=15, verify=False)
        resp.encoding = resp.apparent_encoding or 'utf-8'
        soup = BeautifulSoup(resp.text, 'html.parser')
        p_text = "\n".join([p.get_text(strip=True) for p in soup.find_all("p") if len(p.get_text(strip=True))>10])
        art_text = soup.find("article").get_text(strip=True) if soup.find("article") else ""
        text = p_text if len(p_text) > len(art_text) else art_text
        return re.sub(r'[^\u4e00-\u9fa5\s]', '', re.sub(r'\s+', ' ', text))
    except Exception as e:
        return f"URLæŠ“å–å¤±è´¥ï¼š{str(e)}"

# 2. æ–‡æœ¬åˆ†æ
def analyze_text(text, min_freq=1):
    stop_words = {'çš„','äº†','æ˜¯','åœ¨','å’Œ','æœ‰','å°±','éƒ½','è¿™','é‚£','ä¸ª','ä¸º','æŠŠ','æˆ‘','ä½ ','ä»–','å¥¹','å®ƒ','æˆ‘ä»¬','ä½ ä»¬','ä»–ä»¬','è¿™é‡Œ','é‚£é‡Œ','ä»€ä¹ˆ','æ€ä¹ˆ','ä¸ºä»€ä¹ˆ','å¦‚ä½•','ç„¶å','ä½†æ˜¯','å¦‚æœ','å› ä¸º','æ‰€ä»¥','è™½ç„¶','æ—¢ç„¶','ä¹‹','äº','ä¹Ÿ','è¿˜','åŠ','ä¸','æˆ–','å³','æ‰€','å°†','ä¼š','å¯','èƒ½','åº”','è¯¥','è¦','éœ€','é¡»','å¾—','è¿‡','ç€','å•Š','å‘€','å‘¢','å—','å§'}
    words = [w for w in jieba.lcut(re.sub(r'\s+', ' ', text)) if w not in stop_words and len(w)>1]
    word_freq = Counter(words)
    return {k:v for k,v in word_freq.items() if v>=min_freq}, sorted(word_freq.items(), key=lambda x:x[1], reverse=True)[:20]

# 3. çº¯StreamlitåŸç”Ÿå›¾è¡¨ï¼ˆ8ç§ï¼Œæ— ä»»ä½•ç¬¬ä¸‰æ–¹åº“ï¼‰
def show_chart(top20, chart_type):
    if not top20:
        st.warning("æš‚æ— æœ‰æ•ˆæ•°æ®")
        return
    df = pd.DataFrame(top20, columns=["è¯æ±‡", "è¯é¢‘"])

    # 1. è¯äº‘å›¾ï¼ˆåŸç”Ÿç»„ä»¶ç‰ˆï¼‰
    if chart_type == "è¯äº‘å›¾":
        st.subheader("TOP20è¯æ±‡è¯äº‘å›¾")
        cols = st.columns(5)
        for idx, (word, freq) in enumerate(top20):
            col = cols[idx % 5]
            if freq >= 8:
                col.title(word)
            elif freq >= 5:
                col.header(word)
            else:
                col.subheader(word)

    # 2. æŸ±çŠ¶å›¾ï¼ˆåŸç”Ÿè¡¨æ ¼+è¿›åº¦æ¡ï¼‰
    elif chart_type == "æŸ±çŠ¶å›¾":
        st.subheader("TOP20è¯æ±‡æŸ±çŠ¶å›¾")
        for word, freq in top20:
            st.write(f"**{word}**")
            st.progress(freq / df["è¯é¢‘"].max())

    # 3. æŠ˜çº¿å›¾ï¼ˆåŸç”ŸæŠ˜çº¿ç»„ä»¶ï¼‰
    elif chart_type == "æŠ˜çº¿å›¾":
        st.subheader("TOP20è¯æ±‡æŠ˜çº¿å›¾")
        st.line_chart(df.set_index("è¯æ±‡")["è¯é¢‘"])

    # 4. é¥¼å›¾ï¼ˆåŸç”Ÿé¥¼å›¾ç»„ä»¶ï¼‰
    elif chart_type == "é¥¼å›¾":
        st.subheader("TOP20è¯æ±‡é¥¼å›¾")
        st.pie_chart(df.set_index("è¯æ±‡")["è¯é¢‘"])

    # 5. é›·è¾¾å›¾ï¼ˆåŸç”ŸæŒ‡æ ‡+åˆ†æ ï¼‰
    elif chart_type == "é›·è¾¾å›¾":
        st.subheader("TOP8è¯æ±‡é›·è¾¾å›¾")
        df_radar = df.head(8)
        cols = st.columns(4)
        for idx, (word, freq) in df_radar.iterrows():
            col = cols[idx % 4]
            col.metric(label=word, value=freq)

    # 6. æ•£ç‚¹å›¾ï¼ˆåŸç”Ÿæ•£ç‚¹ç»„ä»¶ï¼‰
    elif chart_type == "æ•£ç‚¹å›¾":
        st.subheader("TOP20è¯æ±‡æ•£ç‚¹å›¾")
        st.scatter_chart(df, x="è¯æ±‡", y="è¯é¢‘", size="è¯é¢‘")

    # 7. çƒ­åŠ›å›¾ï¼ˆåŸç”Ÿé¢œè‰²å—ï¼‰
    elif chart_type == "çƒ­åŠ›å›¾":
        st.subheader("TOP20è¯æ±‡çƒ­åŠ›å›¾")
        cols = st.columns(len(df))
        for idx, (word, freq) in enumerate(top20):
            col = cols[idx]
            col.write(word)
            col.markdown(f"<div style='background:#{int(255-freq*10):02x}e6f9; height:30px;'></div>", unsafe_allow_html=True)

    # 8. æ¼æ–—å›¾ï¼ˆåŸç”Ÿåˆ†æ +é«˜åº¦æ¸å˜ï¼‰
    elif chart_type == "æ¼æ–—å›¾":
        st.subheader("TOP20è¯æ±‡æ¼æ–—å›¾")
        max_freq = df["è¯é¢‘"].max()
        for word, freq in top20:
            height = int(freq / max_freq * 50)
            st.markdown(f"<div style='background:#4285F4; height:{height}px; text-align:center; color:white; line-height:{height}px;'>{word} ({freq})</div>", unsafe_allow_html=True)

# é¡µé¢å¸ƒå±€
st.title("ğŸ“Š URLæ–‡æœ¬è¯é¢‘åˆ†æç³»ç»Ÿ")
st.subheader("StreamlitåŸç”Ÿç‰ˆ | æ— ç¬¬ä¸‰æ–¹ä¾èµ–")

with st.sidebar:
    st.header("âš™ï¸ é…ç½®é¡¹")
    url = st.text_input("æ–‡ç« URL", value="https://www.guokr.com/article/440923/")
    min_freq = st.selectbox("æœ€ä½è¯é¢‘è¿‡æ»¤", [1,2,3,4,5])
    chart_type = st.selectbox("å›¾è¡¨ç±»å‹", ["è¯äº‘å›¾","æŸ±çŠ¶å›¾","æŠ˜çº¿å›¾","é¥¼å›¾","é›·è¾¾å›¾","æ•£ç‚¹å›¾","çƒ­åŠ›å›¾","æ¼æ–—å›¾"])
    analyze_btn = st.button("ğŸš€ æŠ“å–å¹¶åˆ†æ")

# åˆ†æé€»è¾‘
if analyze_btn:
    if not url:
        st.error("è¯·è¾“å…¥æœ‰æ•ˆçš„URLï¼")
    else:
        text = fetch_url_text(url)
        if text.startswith("URLæŠ“å–å¤±è´¥"):
            st.error(text)
        elif len(text) < 50:
            st.warning("URLæ–‡æœ¬è¿‡çŸ­ï¼Œä½¿ç”¨å…œåº•æµ‹è¯•æ–‡æœ¬ï¼")
            text = BACKUP_TEXT
        
        word_freq, top20 = analyze_text(text, min_freq)
        if not top20:
            st.error("æ— æœ‰æ•ˆè¯æ±‡ï¼Œé™ä½è¯é¢‘é‡è¯•ï¼")
        else:
            st.success(f"åˆ†ææˆåŠŸï¼æœ‰æ•ˆè¯æ±‡{len(word_freq)}ä¸ª")
            st.table([{"æ’å":i+1, "è¯æ±‡":w, "è¯é¢‘":f} for i,(w,f) in enumerate(top20)])
            st.subheader(f"{chart_type}å¯è§†åŒ–")
            show_chart(top20, chart_type)
