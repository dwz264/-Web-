# -*- coding: utf-8 -*-
# streamlit_text_analysis.py (æ ¸å¿ƒæ–‡ä»¶)
import streamlit as st
import jieba
import re
from collections import Counter
import pyecharts.options as opts
from pyecharts.charts import WordCloud, Bar, Line, Pie, Radar, Scatter, HeatMap, Funnel
from pyecharts.globals import ThemeType
import requests
from bs4 import BeautifulSoup
from streamlit.components.v1 import html

# é¡µé¢é…ç½®
st.set_page_config(
    page_title="URLæ–‡æœ¬è¯é¢‘åˆ†æç³»ç»Ÿ",
    page_icon="ğŸ“Š",
    layout="wide"
)

# å…œåº•æ–‡æœ¬
BACKUP_TEXT = """äººå·¥æ™ºèƒ½æ˜¯ä¸€é—¨æ—¨åœ¨ä½¿è®¡ç®—æœºç³»ç»Ÿèƒ½å¤Ÿæ¨¡æ‹Ÿã€å»¶ä¼¸å’Œæ‰©å±•äººç±»æ™ºèƒ½çš„æŠ€æœ¯ç§‘å­¦ã€‚å®ƒæ¶µç›–äº†æœºå™¨å­¦ä¹ ã€è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€ä¸“å®¶ç³»ç»Ÿç­‰å¤šä¸ªé¢†åŸŸã€‚æœºå™¨å­¦ä¹ æ˜¯äººå·¥æ™ºèƒ½çš„æ ¸å¿ƒï¼Œé€šè¿‡è®©è®¡ç®—æœºä»æ•°æ®ä¸­å­¦ä¹ æ¨¡å¼ï¼Œè€Œæ— éœ€æ˜¾å¼ç¼–ç¨‹ã€‚æ·±åº¦å­¦ä¹ ä½œä¸ºæœºå™¨å­¦ä¹ çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œä½¿ç”¨ç¥ç»ç½‘ç»œæ¨¡æ‹Ÿäººè„‘ç»“æ„ï¼Œåœ¨å›¾åƒè¯†åˆ«ã€è¯­éŸ³è¯†åˆ«ç­‰é¢†åŸŸå–å¾—äº†çªç ´æ€§è¿›å±•ã€‚è‡ªç„¶è¯­è¨€å¤„ç†åˆ™ä¸“æ³¨äºè®©è®¡ç®—æœºç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€ï¼Œå¦‚èŠå¤©æœºå™¨äººã€æœºå™¨ç¿»è¯‘ç­‰åº”ç”¨ã€‚äººå·¥æ™ºèƒ½çš„å‘å±•å·²ç»æ·±åˆ»å½±å“äº†åŒ»ç–—ã€é‡‘èã€äº¤é€šã€æ•™è‚²ç­‰å„è¡Œå„ä¸šï¼Œæœªæ¥è¿˜å°†ç»§ç»­æ¨åŠ¨ç¤¾ä¼šçš„æ•°å­—åŒ–è½¬å‹ã€‚"""

# 1. URLæ–‡æœ¬æŠ“å–
def fetch_url_text(url):
    try:
        headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) Chrome/86.0.4240.198 Safari/537.36"}
        resp = requests.get(url, headers=headers, timeout=15, verify=False)
        resp.encoding = resp.apparent_encoding or 'utf-8'
        soup = BeautifulSoup(resp.text, 'html.parser')
        p_text = "\n".join([p.get_text(strip=True) for p in soup.find_all("p") if len(p.get_text(strip=True))>10])
        art_text = soup.find("article").get_text(strip=True) if soup.find("article") else ""
        text = p_text if len(p_text) > len(art_text) else art_text
        return re.sub(r'[^\u4e00-\u9fa5\s]', '', re.sub(r'\s+', ' ', text))
    except Exception as e:
        return f"URLæŠ“å–å¤±è´¥ï¼š{str(e)}"

# 2. æ–‡æœ¬åˆ†æ
def analyze_text(text, min_freq=1):
    stop_words = {'çš„','äº†','æ˜¯','åœ¨','å’Œ','æœ‰','å°±','éƒ½','è¿™','é‚£','ä¸ª','ä¸º','æŠŠ','æˆ‘','ä½ ','ä»–','å¥¹','å®ƒ','æˆ‘ä»¬','ä½ ä»¬','ä»–ä»¬','è¿™é‡Œ','é‚£é‡Œ','ä»€ä¹ˆ','æ€ä¹ˆ','ä¸ºä»€ä¹ˆ','å¦‚ä½•','ç„¶å','ä½†æ˜¯','å¦‚æœ','å› ä¸º','æ‰€ä»¥','è™½ç„¶','æ—¢ç„¶','ä¹‹','äº','ä¹Ÿ','è¿˜','åŠ','ä¸','æˆ–','å³','æ‰€','å°†','ä¼š','å¯','èƒ½','åº”','è¯¥','è¦','éœ€','é¡»','å¾—','è¿‡','ç€','å•Š','å‘€','å‘¢','å—','å§'}
    words = [w for w in jieba.lcut(re.sub(r'\s+', ' ', text)) if w not in stop_words and len(w)>1]
    word_freq = Counter(words)
    return {k:v for k,v in word_freq.items() if v>=min_freq}, sorted(word_freq.items(), key=lambda x:x[1], reverse=True)[:20]

# 3. ç”Ÿæˆå›¾è¡¨
def generate_chart_html(top20, chart_type):
    if not top20:
        return "<div style='text-align:center;padding:50px;color:#666;'>æš‚æ— æœ‰æ•ˆæ•°æ®</div>"
    
    words, freqs = [i[0] for i in top20], [i[1] for i in top20]
    max_freq = max(freqs) if freqs else 1

    # ç”Ÿæˆå›¾è¡¨ï¼ˆæ”¹ç”¨render_notebookï¼Œé€‚é…Streamlitï¼‰
    if chart_type == "è¯äº‘å›¾":
        c = WordCloud(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="800", height="500"))
        c.add("è¯é¢‘", top20, word_size_range=[20, 80])
        c.set_global_opts(title_opts=opts.TitleOpts(title="TOP20è¯æ±‡è¯äº‘å›¾"))
    elif chart_type == "æŸ±çŠ¶å›¾":
        c = Bar(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="800", height="500"))
        c.add_xaxis(words)
        c.add_yaxis("è¯é¢‘", freqs)
        c.reversal_axis()
        c.set_global_opts(title_opts=opts.TitleOpts(title="TOP20è¯æ±‡æŸ±çŠ¶å›¾"))
    elif chart_type == "æŠ˜çº¿å›¾":
        c = Line(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="800", height="500"))
        c.add_xaxis(words)
        c.add_yaxis("è¯é¢‘", freqs)
        c.set_global_opts(title_opts=opts.TitleOpts(title="TOP20è¯æ±‡æŠ˜çº¿å›¾"))
    elif chart_type == "é¥¼å›¾":
        c = Pie(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="800", height="500"))
        c.add("", list(zip(words, freqs)), radius=["30%", "70%"])
        c.set_global_opts(title_opts=opts.TitleOpts(title="TOP20è¯æ±‡é¥¼å›¾"))
    elif chart_type == "é›·è¾¾å›¾":
        c = Radar(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="800", height="500"))
        c.add_schema(schema=[{"name": w, "max": max_freq} for w in words[:8]])
        c.add("è¯é¢‘", [freqs[:8]])
        c.set_global_opts(title_opts=opts.TitleOpts(title="TOP8è¯æ±‡é›·è¾¾å›¾"))
    elif chart_type == "æ•£ç‚¹å›¾":
        c = Scatter(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="800", height="500"))
        c.add_xaxis(words)
        c.add_yaxis("è¯é¢‘", freqs, symbol_size=lambda x: x*5)
        c.set_global_opts(title_opts=opts.TitleOpts(title="TOP20è¯æ±‡æ•£ç‚¹å›¾"), visualmap_opts=opts.VisualMapOpts(max_=max_freq))
    elif chart_type == "çƒ­åŠ›å›¾":
        c = HeatMap(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="800", height="500"))
        c.add_xaxis(words)
        c.add_yaxis("è¯é¢‘", ["é¢‘æ¬¡"], [[i, 0, v] for i, v in enumerate(freqs)])
        c.set_global_opts(title_opts=opts.TitleOpts(title="TOP20è¯æ±‡çƒ­åŠ›å›¾"), visualmap_opts=opts.VisualMapOpts(max_=max_freq))
    elif chart_type == "æ¼æ–—å›¾":
        c = Funnel(init_opts=opts.InitOpts(theme=ThemeType.LIGHT, width="800", height="500"))
        c.add("è¯é¢‘", top20)
        c.set_global_opts(title_opts=opts.TitleOpts(title="TOP20è¯æ±‡æ¼æ–—å›¾"))

    # ç”Ÿæˆé€‚åˆStreamlitçš„HTMLï¼ˆå…³é”®ä¿®å¤ï¼‰
    return c.render_notebook()
# ======== Streamlité¡µé¢å¸ƒå±€ ========
st.title("ğŸ“Š URLæ–‡æœ¬è¯é¢‘åˆ†æç³»ç»Ÿ")
st.subheader("Streamlit Cloudéƒ¨ç½²ç‰ˆ | æ”¯æŒ8ç§å›¾è¡¨å¯è§†åŒ–")

# è¾“å…¥åŒºåŸŸ
with st.sidebar:
    st.header("âš™ï¸ é…ç½®é¡¹")
    url = st.text_input("æ–‡ç« URL", value="https://www.guokr.com/article/440923/", placeholder="è¾“å…¥å…¬å¼€ä¸­æ–‡æ–‡ç« URL")
    min_freq = st.selectbox("æœ€ä½è¯é¢‘è¿‡æ»¤", options=[1,2,3,4,5], index=0)
    chart_type = st.selectbox("å›¾è¡¨ç±»å‹", options=["è¯äº‘å›¾","æŸ±çŠ¶å›¾","æŠ˜çº¿å›¾","é¥¼å›¾","é›·è¾¾å›¾","æ•£ç‚¹å›¾","çƒ­åŠ›å›¾","æ¼æ–—å›¾"], index=0)
    analyze_btn = st.button("ğŸš€ æŠ“å–å¹¶åˆ†æ", type="primary")

# åˆ†æé€»è¾‘
if analyze_btn:
    if not url:
        st.error("âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„URLï¼")
    else:
        with st.spinner("ğŸ” æ­£åœ¨æŠ“å–URLæ–‡æœ¬..."):
            text = fetch_url_text(url)
        
        if text.startswith("URLæŠ“å–å¤±è´¥"):
            st.error(f"âŒ {text}")
        elif len(text) < 50:
            st.warning(f"âš ï¸ URLæ–‡æœ¬è¿‡çŸ­ï¼ˆ{len(text)}å­—ï¼‰ï¼Œä½¿ç”¨å…œåº•æµ‹è¯•æ–‡æœ¬ï¼")
            text = BACKUP_TEXT
        
        # åˆ†è¯åˆ†æ
        word_freq, top20 = analyze_text(text, min_freq)
        if not top20:
            st.error("âŒ æ— æœ‰æ•ˆè¯æ±‡ï¼Œé™ä½è¯é¢‘é‡è¯•ï¼")
        else:
            st.success(f"âœ… åˆ†ææˆåŠŸï¼æœ‰æ•ˆè¯æ±‡{len(word_freq)}ä¸ªï¼Œå±•ç¤ºï¼š{chart_type}")
            
            # å±•ç¤ºç»Ÿè®¡ä¿¡æ¯
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("æœ‰æ•ˆè¯æ±‡æ€»æ•°", len(word_freq))
            with col2:
                st.metric("æœ€é«˜è¯é¢‘", top20[0][1])
            with col3:
                st.metric("å±•ç¤ºè¯æ±‡æ•°", 20)
            
            # å±•ç¤ºTOP20è¡¨æ ¼
            st.subheader("ğŸ“‹ TOP20è¯æ±‡åˆ—è¡¨")
            st.table([{"æ’å":i+1, "è¯æ±‡":w, "è¯é¢‘":f} for i,(w,f) in enumerate(top20)])
            
            # å±•ç¤ºå›¾è¡¨
            st.subheader(f"ğŸ“ˆ {chart_type}å¯è§†åŒ–")
            chart_html = generate_chart_html(top20, chart_type)
            html(chart_html, width=850, height=550)

# é¡µè„š
st.divider()

st.caption("ğŸ’¡ éƒ¨ç½²äºStreamlit Cloud | æ”¯æŒ32ä½ç³»ç»Ÿå…¼å®¹")

